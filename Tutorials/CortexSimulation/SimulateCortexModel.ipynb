{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating the Cortex Model\n",
    "\n",
    "This is the ipython notebook that supplements the tutorial [Cortex Simulation](https://matisse.eecs.berkeley.edu/tutorials/3_CortexSimulation.html).\n",
    "\n",
    "Before running these codes, please make sure you have installed the required packages and set up the environment as described in the [Getting Started](https://matisse.eecs.berkeley.edu/tutorials/1_GettingStarted.html).\n",
    "\n",
    "Also, make sure you have selected the correct python kernel (e.g. `MatisseEnv`).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate retina and cortex models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Simulated.Retina.RetinaModel import RetinaModel\n",
    "from Simulated.Cortex.CortexModel import CortexModel\n",
    "\n",
    "# Load the default parameters for the trichromatic retina simulation\n",
    "with open(f'{ROOT_DIR}/Experiment/Config/Default/LMS.yaml', 'r') as f:\n",
    "    params = yaml.safe_load(f)\n",
    "\n",
    "# Initialize the retina model\n",
    "retina = RetinaModel(params, device=DEVICE)\n",
    "\n",
    "# Initialize the cortex model\n",
    "cortex = CortexModel(params, device=DEVICE)\n",
    "cortex = torch.compile(cortex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can change the example_image_path to the path of your own image\n",
    "example_image_path = f'{ROOT_DIR}/Tutorials/data/sample_sRGB_image.png'\n",
    "example_sRGB_image = load_sRGB_image(retina, example_image_path, params).to(DEVICE)\n",
    "\n",
    "# retina.CST (color space transform) is used to convert the color space\n",
    "# In this case, we convert the sRGB image to linsRGB, and then to LMS\n",
    "example_linsRGB_image = retina.CST.sRGB_to_linsRGB(example_sRGB_image)\n",
    "example_LMS_image = retina.CST.linsRGB_to_LMS(example_linsRGB_image)\n",
    "example_LMS_image = example_LMS_image.unsqueeze(0).permute(0, 3, 1, 2)\n",
    "\n",
    "with torch.no_grad(): # gradient computation is not needed for retina simulation\n",
    "    list_of_retinal_responses = retina.forward(example_LMS_image, intermediate_outputs=True)\n",
    "    optic_nerve_signals = list_of_retinal_responses[0]\n",
    "\n",
    "optic_nerve_signals = optic_nerve_signals[:,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_percepts = []\n",
    "\n",
    "\n",
    "for num_gradient_updates in tqdm(range(0, 100001, 100), desc='Generating learned percepts... '):\n",
    "    if os.path.exists(f'{ROOT_DIR}/Experiment/LearnedWeights/LMS/{num_gradient_updates}.pt'):\n",
    "\n",
    "        # Load the pre-trained weights for the default cortex model\n",
    "        cortex.load_state_dict(torch.load(f'{ROOT_DIR}/Experiment/LearnedWeights/LMS/{num_gradient_updates}.pt', weights_only=True, map_location=DEVICE))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            warped_internal_percept = cortex.decode(optic_nerve_signals)\n",
    "\n",
    "            # internal percept is N-channel image, where N is the latent dimension (N is formally defined in the paper)\n",
    "            # We use the ns_ip module (neural scope for internal percept) to project the percept to the linsRGB space\n",
    "            warped_internal_percept_linsRGB = cortex.ns_ip.forward(warped_internal_percept)\n",
    "\n",
    "            # Then we use the retina.CST (color space transform) to convert the linsRGB space to the sRGB space\n",
    "            warped_internal_percept_sRGB = retina.CST.linsRGB_to_sRGB(warped_internal_percept_linsRGB)\n",
    "\n",
    "            # get_unwarped_percept is a helper function defined in the ipython notebook file\n",
    "            internal_percept_sRGB = get_unwarped_percept(warped_internal_percept_sRGB, cortex)\n",
    "\n",
    "            learned_percepts.append([num_gradient_updates, internal_percept_sRGB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_percept_sRGB = get_unwarped_percept(warped_internal_percept_sRGB, cortex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{ROOT_DIR}/Tutorials/CortexSimulation/Results/LP', exist_ok=True)\n",
    "# Visualize the learned percepts as a mp4 movie\n",
    "\n",
    "for [num_gradient_updates, learned_percept] in learned_percepts:\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    plt.imshow(learned_percept)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Learned Percept at {num_gradient_updates:06d} gradient updates')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{ROOT_DIR}/Tutorials/CortexSimulation/Results/LP/learned_percept_{num_gradient_updates:06d}.png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the images to a mp4 movie\n",
    "images = [imageio.imread(f'{ROOT_DIR}/Tutorials/CortexSimulation/Results/LP/learned_percept_{timestep:06d}.png') for [timestep, _] in learned_percepts]\n",
    "imageio.mimsave(f'{ROOT_DIR}/Tutorials/CortexSimulation/Results/learned_percept.gif', images, fps=10, loop=0)\n",
    "\n",
    "subprocess.run(['ffmpeg', '-y', '-i', f'{ROOT_DIR}/Tutorials/CortexSimulation/Results/learned_percept.gif', '-vf', 'fps=10', '-c:v', 'libx264', '-pix_fmt', 'yuv420p', f'{ROOT_DIR}/Tutorials/CortexSimulation/Results/LP/learned_percept.mp4'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the movie\n",
    "IPython.display.Image(filename=f'{ROOT_DIR}/Tutorials/CortexSimulation/Results/learned_percept.gif')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HumanColorVision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
